{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manjunath727/DL/blob/master/2/3_Backprop_1\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jtqb8HjKtoJZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "0b48b285-9b39-483c-da32-30f8d1234b4c"
      },
      "cell_type": "code",
      "source": [
        "# Implementing Back-Propagation\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "# Data placeholders and A the variable\n",
        "x_vals = np.random.normal(1, 0.1, 100)\n",
        "y_vals = np.repeat(10., 100)\n",
        "x_data = tf.placeholder(shape=[1], dtype=tf.float32)\n",
        "y_target = tf.placeholder(shape=[1], dtype=tf.float32)\n",
        "A = tf.Variable(tf.random_normal(shape=[1]))\n",
        "\n",
        "# Add multiplication\n",
        "my_output = tf.multiply(x_data, A)\n",
        "\n",
        "# L2 loss function\n",
        "loss = tf.square(my_output - y_target)\n",
        "\n",
        "# Initialize all the variables\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "# Gradient Descent Optimizer\n",
        "my_opt = tf.train.GradientDescentOptimizer(learning_rate = 0.02)\n",
        "train_step = my_opt.minimize(loss)\n",
        "\n",
        "# Loop through the training algorithm\n",
        "for i in range(100):\n",
        "  rand_index = np.random.choice(100)\n",
        "  rand_x = [x_vals[rand_index]]\n",
        "  rand_y = [y_vals[rand_index]]\n",
        "  sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
        "  if (i+1)%25 == 0:\n",
        "    print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
        "    print('Loss #' + str(sess.run(loss, feed_dict={x_data:rand_x, y_target:rand_y})))\n",
        "  \n",
        " \n",
        "\n",
        "    \n",
        "    \n",
        "   \n",
        "     \n",
        "     "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step #25 A = [7.23743]\n",
            "Loss #[7.5148726]\n",
            "Step #50 A = [8.945288]\n",
            "Loss #[2.3367367]\n",
            "Step #75 A = [9.665263]\n",
            "Loss #[0.2523362]\n",
            "Step #100 A = [9.757427]\n",
            "Loss #[0.00722241]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}